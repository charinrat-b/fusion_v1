{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from random import shuffle\n",
    "\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.utils import Sequence, to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train files: 918\n",
      "Eval files: 606\n",
      "Labels: 300\n"
     ]
    }
   ],
   "source": [
    "IMAGES_DIR = os.path.join(\"..\", \"datasets\", \"CASIA-PalmprintV1\")\n",
    "num_classes = 300\n",
    "\n",
    "def train_test_split():\n",
    "    labels = sorted(os.listdir(IMAGES_DIR))[:num_classes]\n",
    "    train_files = []\n",
    "    eval_files = []\n",
    "    for label in labels:\n",
    "        folder = os.path.join(IMAGES_DIR, label)\n",
    "        files = [os.path.join(folder, file) for file in os.listdir(folder) if file.endswith(\".jpg\")]\n",
    "        shuffle(files)\n",
    "        split_idx = int(len(files) * 0.7)\n",
    "        train_files.extend(files[:split_idx])\n",
    "        eval_files.extend(files[split_idx:])\n",
    "    return train_files, eval_files, labels\n",
    "\n",
    "train_files, eval_files, labels = train_test_split()\n",
    "print(\"Train files: {}\".format(len(train_files)))\n",
    "print(\"Eval files: {}\".format(len(eval_files)))\n",
    "print(\"Labels: {}\".format(len(labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1524/1524 [00:07<00:00, 207.93it/s]\n"
     ]
    }
   ],
   "source": [
    "image_by_filename = {}\n",
    "files = train_files + eval_files\n",
    "for file in tqdm(files):\n",
    "    image = cv2.imread(file)\n",
    "    image = cv2.resize(image, (224, 224)).astype(np.float32)\n",
    "    image /= 255.\n",
    "    image_by_filename[file] = image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PersonIDSequence(Sequence):\n",
    "\n",
    "    def __init__(self, files, labels, batch_size, extract_palm=False):\n",
    "        self.files = files\n",
    "        self.labels = labels\n",
    "        shuffle(self.files)\n",
    "        self.num_labels = len(self.labels)\n",
    "        self.batch_size = batch_size\n",
    "        self.extract_palm = extract_palm\n",
    "\n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.files) / self.batch_size)\n",
    "\n",
    "    def load_palm_print(self, image_file):\n",
    "        if INPUT_SHAPE[2] == 1:\n",
    "            image = cv2.imread(image_file, 0)\n",
    "        else:\n",
    "            image = cv2.imread(image_file)\n",
    "        if self.extract_palm:\n",
    "            image = extract_palm_from_img(image)\n",
    "        try:\n",
    "            image = cv2.resize(image, INPUT_SHAPE[:2])\n",
    "        except:\n",
    "            print(\"image_file:\", image_file)\n",
    "        image = image * 1./255\n",
    "        return image\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X = self.files[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        y = [os.path.basename(os.path.dirname(file)) for file in X ]\n",
    "        palm_prints = np.array([image_by_filename[image] for image in X])\n",
    "        y_indices = [to_categorical(self.labels.index(i), num_classes=self.num_labels)\n",
    "                     for i in y]\n",
    "        return palm_prints, np.array(y_indices)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        shuffle(self.files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE = (224, 224, 3)\n",
    "\n",
    "def palm_model():\n",
    "    vgg16 = VGG16(include_top=False, weights='imagenet', input_shape=INPUT_SHAPE)\n",
    "    for layer in vgg16.layers:\n",
    "        layer.trainable = False\n",
    "    x = vgg16.output\n",
    "    x = layers.Flatten()(x)                                # Flatten dimensions to for use in FC layers\n",
    "    x = layers.Dense(4096, activation='relu')(x)\n",
    "    x = layers.Dense(4096, activation='relu')(x)\n",
    "    x = layers.Dropout(0.2)(x)                             # Dropout layer to reduce overfitting\n",
    "    x = layers.Dense(len(labels), name=\"last_dense\")(x) \n",
    "    x = layers.Softmax()(x)                                # Softmax for multiclass\n",
    "    return Model(inputs=vgg16.input, outputs=x)\n",
    "\n",
    "model = palm_model()\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = PersonIDSequence(train_files, labels, batch_size=64)\n",
    "eval_ds = PersonIDSequence(eval_files, labels, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - ETA: 0s - loss: 6.0076 - accuracy: 0.0120 "
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "lr = 0.0001\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=Adam(lr))\n",
    "history = model.fit(train_ds, epochs=epochs, validation_data=eval_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 7s 268ms/step - loss: 0.3701 - accuracy: 0.9331\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.37008239386173397, 0.9331269]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(eval_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"palm_model_e{}_lr{}.h5\".format(epochs, lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf2.0)",
   "language": "python",
   "name": "tf2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
